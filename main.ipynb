{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "\n",
    "Recommendation System are of two types - \n",
    "\n",
    "- Content Based - Based Current Content you are watching\n",
    "\n",
    "- Collaborative Based - Based on what users like you watch\n",
    "\n",
    "- Hybrid - Mix of Both\n",
    "\n",
    "In this Project, we will be using content based recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Flow (Overview of Things)\n",
    "\n",
    " - Data which we will preprocess to minimise error\n",
    " - Building Model by Training and Testing\n",
    " - Converting to a website\n",
    " - Deploying it on Heroku\n",
    "\n",
    " Dataset Used - TMDB 5000 Movie Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe to work upon\n",
    "movies = pd.read_csv('./tmdb_5000_movies.csv')\n",
    "credit = pd.read_csv('./tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging both data frames\n",
    "movies = movies.merge(credit, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unwanted Columns\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing Missing Data\n",
    "movies.dropna(inplace = True)\n",
    "\n",
    "#removing Duplicate Data (No Duplicates)\n",
    "duplicate_count = movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to extract specific words we want from our dataframes columns\n",
    "def extract(obj):\n",
    "    genres = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        genres.append(i['name'])\n",
    "    return genres\n",
    "\n",
    "#helper function to extract top 3 cast members\n",
    "def extract_cast(obj):\n",
    "    cast = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            cast.append(i['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return cast\n",
    "\n",
    "#helper function to extract director\n",
    "def extract_director(obj):\n",
    "    director = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job'] == 'Director':\n",
    "            director.append(i['name'])\n",
    "            break\n",
    "    return director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting genres as words by calling the helper function above\n",
    "movies['genres'] = movies['genres'].apply(extract)\n",
    "\n",
    "#same for keywords\n",
    "movies['keywords'] = movies['keywords'].apply(extract)\n",
    "\n",
    "#now for cast\n",
    "movies['cast'] = movies['cast'].apply(extract_cast)\n",
    "\n",
    "#now for director\n",
    "movies['crew'] = movies['crew'].apply(extract_director)\n",
    "\n",
    "#now overview as words\n",
    "movies['overview'] = movies['overview'].apply(lambda x:x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing spaces in between names, genres etc to optimise it better\n",
    "movies['genres'] = movies['genres'].apply(lambda x:[i.replace(' ', '') for i in x])\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(' ', '') for i in x])\n",
    "movies['cast'] = movies['cast'].apply(lambda x:[i.replace(' ', '') for i in x])\n",
    "movies['crew'] = movies['crew'].apply(lambda x:[i.replace(' ', '') for i in x])\n",
    "#no need for overview as it doesn't have any spaces left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging all those columns into tags\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "\n",
    "#extracting all the necessary columns out\n",
    "movies = movies[['movie_id', 'title', 'tags']]\n",
    "\n",
    "#converting tags back to lower case strings\n",
    "movies['tags'] = movies['tags'].apply(lambda x: (\" \".join(x).lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model\n",
    "\n",
    "Approaches -\n",
    "\n",
    "- Find Similar words and sort with highest\n",
    "- Text Vectorization and finding similar (closest) vectors\n",
    "\n",
    "We will go with Text Vectorization here\n",
    "\n",
    "# Text Vectorization\n",
    "\n",
    "We will use bag of words technique here\n",
    "\n",
    "Bag of words Basic Algorithm -\n",
    "\n",
    "- combine all tags\n",
    "- find most common words (excluding stop words*, and stemming these words**)\n",
    "- find frequency of all those words in all movies and create a dataframe\n",
    "- find closest vectors which will be our recommended movies (Instead of Euclidean*** distance, we will calculate cosine**** distance)\n",
    "\n",
    "*stop words - words like in, are, a, we, it etc as they do not contribute much to the meaning of sentences\n",
    "\n",
    "**stemming - combining words like 'action', 'actions' which would be considered as different into one to improve efficiency. will be done before Vectorizing\n",
    "\n",
    "***Euclidan = Normal Distance. Not reliable in higher dimensions\n",
    "\n",
    "****Cosine Distance = Distance in terms of angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to stem our tags\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    tags = []\n",
    "    for i in text.split():\n",
    "        tags.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming our tags\n",
    "movies['tags'] = movies['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a Vectorizer Function\n",
    "#max_features - number of words, stop_words - which language we are considering\n",
    "cv = CountVectorizer(max_features = 5000, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the common words along with their frequency. we don't have access to words themselves but to their frequency array as the individual words do not matter to us. we are only concerned with their frequencies\n",
    "#matrix would be sparse as 5000 words will not be there in every movie's tags\n",
    "vectors = cv.fit_transform(movies['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to give us words\n",
    "#cv.get_feature_names_out() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse of distance. gives values between 0-1 1 being same and 0 being opposite. will give a matrix with distance of each movies with each movie. Diagonal will always be 1\n",
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for name in title column. if found then that row will be fetched. of that row we are fetching the item at 0th index which is the index of that movie in dataframe\n",
    "\n",
    "# movies['title'] == 'Avatar' will give the indexes which match with the title\n",
    "\n",
    "# movies[movies['title'] == 'Avatar'] will give whole row as we are passing the index which we want from it\n",
    "\n",
    "# movies[movies['title'] == 'Avatar'].index[0] will give just the index \n",
    "\n",
    "# we will get the index, from that we will get it's distances from similarity and then sort them based on their distance value while keeping its index with it so that we can fetch the recommended movies from our dataframe\n",
    "\n",
    "def recommend(movie):\n",
    "    movie_index = movies[movies['title'] == movie].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    movie_list = sorted(list(enumerate(distances)), reverse = True, key = lambda x: x[1])[1:6]\n",
    "    \n",
    "    for index, similarity_score in movie_list:\n",
    "        print(f'\"{movies.iloc[index]['title']}\" matches with a score of {similarity_score * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Aliens vs Predator: Requiem\" matches with a score of 28.676966733820226\n",
      "\"Aliens\" matches with a score of 26.901379342448518\n",
      "\"Falcon Rising\" matches with a score of 26.051302464767538\n",
      "\"Independence Day\" matches with a score of 25.560859370538303\n",
      "\"Titan A.E.\" matches with a score of 25.03866978335957\n"
     ]
    }
   ],
   "source": [
    "movie_name = input(\"Enter Movie Name (Be vary of Title, Should Match in case spacing etc) - \")\n",
    "recommend(movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting titlea\n",
    "pickle.dump(movies.to_dict(), open('./movies_dict.pkl', 'wb'))\n",
    "\n",
    "#exporting selection matrix\n",
    "pickle.dump(similarity, open(\"./similarity.pkl\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
